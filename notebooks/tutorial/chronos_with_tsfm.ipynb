{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c80d7-878b-4ad0-9f9e-e7592a6aea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "  \"amazon/chronos-t5-tiny\",\n",
    "  # device_map=\"cuda\",\n",
    "  # torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "\n",
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "context = torch.tensor(df[\"#Passengers\"])\n",
    "prediction_length = 12\n",
    "forecast = pipeline.predict(context, prediction_length)  # shape [num_series, num_samples, prediction_length]\n",
    "\n",
    "# visualize the forecast\n",
    "forecast_index = range(len(df), len(df) + prediction_length)\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a262d-6f5d-4b99-9dfe-caf42d36e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tsfm_public import TimeSeriesForecastingPipeline\n",
    "from tsfm_public.toolkit.visualization import plot_predictions\n",
    "from chronos import ChronosPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74b7cf-62c5-42cc-8481-b67d3df926fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36be62-6d7a-47e9-b849-fd0542f7a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_column = \"time\"\n",
    "target_columns = [\"total load actual\"]\n",
    "context_length = 512\n",
    "prediction_length=96 # new param\n",
    "batch_size=16 # new param \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4add6f9-a02d-47fb-97e8-ccb55a652a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the downloaded file.\n",
    "input_df = pd.read_csv(\n",
    "  DATA_FILE_PATH,\n",
    "  parse_dates=[timestamp_column], # Parse the timestamp values as dates. \n",
    ")\n",
    "\n",
    "# Fill NA/NaN values by propagating the last valid value.\n",
    "input_df = input_df.ffill()\n",
    "\n",
    "# Only use the last `context_length` rows for prediction.\n",
    "input_df = input_df.iloc[-context_length:,]\n",
    "\n",
    "# Show the last few rows of the dataset.\n",
    "input_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03a01e-b6d7-450d-b5fb-58c4dc286cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a4095-7924-4b3c-9715-4935d2bebabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(target_columns), 1, figsize=(10, 2 * len(target_columns)), squeeze=False)\n",
    "for ax, target_column in zip(axs, target_columns):\n",
    "    ax[0].plot(input_df[timestamp_column], input_df[target_column])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "873029d7-233e-47e0-bb5e-2f233bfd02f9",
   "metadata": {},
   "source": [
    "\n",
    "zeroshot_model = ChronosPipeline.from_pretrained(\n",
    "  \"amazon/chronos-t5-tiny\",\n",
    "  # device_map=\"cuda\",\n",
    "  # torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e93b3-d0a9-4242-972b-deaec9813647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(zeroshot_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869ecc6-5160-4bb5-b268-df8e4c643353",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TimeSeriesForecastingPipeline(\n",
    "    zeroshot_model.model,\n",
    "    timestamp_column=timestamp_column,\n",
    "    id_columns=[],\n",
    "    target_columns=target_columns,\n",
    "    explode_forecasts=True,\n",
    "    freq=\"h\",\n",
    "    device=\"cpu\", # Specify your local GPU or CPU.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c7db1-71bd-49e4-ab0b-99922be45cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_forecast = pipeline(input_df)\n",
    "zeroshot_forecast.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e164f-2944-4aaf-a881-42ef24d45603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the historical data and predicted series.\n",
    "plot_predictions(\n",
    "    input_df=input_df,\n",
    "    exploded_predictions_df=zeroshot_forecast,\n",
    "    freq=\"h\",\n",
    "    timestamp_column=timestamp_column,\n",
    "    channel=target_column,\n",
    "    indices=[-1],\n",
    "    num_plots=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
